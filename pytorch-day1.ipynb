{"cells":[{"metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch.utils.data import Dataset\nfrom torch.utils.data import DataLoader","execution_count":235,"outputs":[]},{"metadata":{"_uuid":"d629ff2d2480ee46fbb7e2d37f6b5fab8052498a","_cell_guid":"79c7e3d0-c299-4dcb-8224-4455121ee9b0","trusted":true},"cell_type":"code","source":"x_train = torch.FloatTensor([[1],[2],[3]])","execution_count":236,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"y_train = torch.FloatTensor([[2],[4],[6]])","execution_count":237,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W = torch.zeros(1, requires_grad=True)\nb = torch.zeros(1, requires_grad=True)","execution_count":238,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.SGD([W,b], lr=0.01)","execution_count":239,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"epochs = 20\nlr = 0.001","execution_count":240,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(1,epochs+1):\n#     hypothesis = x_train * W + b\n    hypothesis = x_train * W\n    \n    cost = torch.mean((hypothesis - y_train) ** 2)\n#     gradient = torch.sum((W * x_train - y_train) * x_train)    \n#     W = W - lr * gradient\n    \n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n    print(f'{epoch}/{epochs} W: {W.item()}, cost: {cost.item()}')\n#     print(f'{epoch}/{epochs} W: {W.item()}, b:{b.item()} cost: {cost.item()}')\n    \n    ","execution_count":241,"outputs":[{"output_type":"stream","text":"1/20 W: 0.18666668236255646, cost: 18.66666603088379\n2/20 W: 0.35591110587120056, cost: 15.344829559326172\n3/20 W: 0.5093594193458557, cost: 12.614131927490234\n4/20 W: 0.6484858989715576, cost: 10.369377136230469\n5/20 W: 0.7746272087097168, cost: 8.524088859558105\n6/20 W: 0.888995349407196, cost: 7.007179260253906\n7/20 W: 0.9926891326904297, cost: 5.760212421417236\n8/20 W: 1.0867048501968384, cost: 4.7351508140563965\n9/20 W: 1.1719456911087036, cost: 3.8925039768218994\n10/20 W: 1.2492307424545288, cost: 3.1998116970062256\n11/20 W: 1.3193025588989258, cost: 2.630387544631958\n12/20 W: 1.3828343152999878, cost: 2.162295341491699\n13/20 W: 1.4404364824295044, cost: 1.7775030136108398\n14/20 W: 1.4926624298095703, cost: 1.4611860513687134\n15/20 W: 1.5400139093399048, cost: 1.201159954071045\n16/20 W: 1.5829459428787231, cost: 0.9874069094657898\n17/20 W: 1.621870994567871, cost: 0.8116922974586487\n18/20 W: 1.6571630239486694, cost: 0.6672472357749939\n19/20 W: 1.6891611814498901, cost: 0.5485069751739502\n20/20 W: 1.7181727886199951, cost: 0.4508970081806183\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"# multi variable linear regression","execution_count":242,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"x_train2 = torch.FloatTensor([[73,80,75],\n                             [93,88,93],\n                             [89,91,90],\n                             [96,98,100],\n                             [73,66,70]])\ny_train2 = torch.FloatTensor([[152],[185],[180],[196],[142]])","execution_count":243,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"W = torch.zeros((3,1), requires_grad=True)\nb = torch.zeros(1, requires_grad=True)","execution_count":244,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.SGD([W,b], lr=0.00001)","execution_count":245,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(1,epochs+1):\n    hypothesis = x_train2.matmul(W) + b    \n    cost = torch.mean((hypothesis - y_train2) ** 2)\n    \n    optimizer.zero_grad()\n    cost.backward()\n    optimizer.step()\n    print(f'{epoch}/{epochs} hypothesis:{hypothesis.squeeze().detach()} cost: {cost.item()}')\n    \n    ","execution_count":246,"outputs":[{"output_type":"stream","text":"1/20 hypothesis:tensor([0., 0., 0., 0., 0.]) cost: 29661.80078125\n2/20 hypothesis:tensor([67.2578, 80.8397, 79.6523, 86.7394, 61.6605]) cost: 9298.5205078125\n3/20 hypothesis:tensor([104.9128, 126.0990, 124.2466, 135.3015,  96.1821]) cost: 2915.71240234375\n4/20 hypothesis:tensor([125.9942, 151.4381, 149.2133, 162.4896, 115.5097]) cost: 915.04052734375\n5/20 hypothesis:tensor([137.7967, 165.6247, 163.1911, 177.7112, 126.3307]) cost: 287.93609619140625\n6/20 hypothesis:tensor([144.4044, 173.5674, 171.0168, 186.2332, 132.3891]) cost: 91.37106323242188\n7/20 hypothesis:tensor([148.1035, 178.0143, 175.3980, 191.0042, 135.7812]) cost: 29.758249282836914\n8/20 hypothesis:tensor([150.1744, 180.5042, 177.8509, 193.6753, 137.6805]) cost: 10.445266723632812\n9/20 hypothesis:tensor([151.3336, 181.8983, 179.2240, 195.1707, 138.7440]) cost: 4.391237258911133\n10/20 hypothesis:tensor([151.9824, 182.6789, 179.9928, 196.0079, 139.3396]) cost: 2.493121385574341\n11/20 hypothesis:tensor([152.3454, 183.1161, 180.4231, 196.4765, 139.6732]) cost: 1.8976879119873047\n12/20 hypothesis:tensor([152.5485, 183.3609, 180.6640, 196.7389, 139.8602]) cost: 1.7105515003204346\n13/20 hypothesis:tensor([152.6620, 183.4982, 180.7988, 196.8857, 139.9651]) cost: 1.6514164209365845\n14/20 hypothesis:tensor([152.7253, 183.5752, 180.8742, 196.9678, 140.0240]) cost: 1.632368803024292\n15/20 hypothesis:tensor([152.7606, 183.6184, 180.9164, 197.0138, 140.0571]) cost: 1.625923752784729\n16/20 hypothesis:tensor([152.7802, 183.6427, 180.9399, 197.0395, 140.0759]) cost: 1.6234203577041626\n17/20 hypothesis:tensor([152.7909, 183.6565, 180.9530, 197.0538, 140.0865]) cost: 1.6221520900726318\n18/20 hypothesis:tensor([152.7968, 183.6643, 180.9603, 197.0618, 140.0927]) cost: 1.6212615966796875\n19/20 hypothesis:tensor([152.7999, 183.6688, 180.9644, 197.0661, 140.0963]) cost: 1.6205012798309326\n20/20 hypothesis:tensor([152.8014, 183.6715, 180.9665, 197.0686, 140.0985]) cost: 1.6197574138641357\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"class MultivariateLinearRegressionModel(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.linear = nn.Linear(3,1)\n        \n    def forward(self,x):\n        return self.linear(x)\n\n","execution_count":247,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"model = MultivariateLinearRegressionModel()","execution_count":248,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"optimizer = torch.optim.SGD(model.parameters(), lr=1e-5)","execution_count":249,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"# for epoch in range(epochs +1):\n#     Hypothesis = model(x_train2)\n    \n#     cost = F.mse_loss(Hypothesis, y_train2)\n    \n#     optimizer.zero_grad()\n#     cost.backward()\n#     optimizer.step()\n    \n#     print(f'{epoch}/{epochs} hypothesis:{Hypothesis.squeeze().detach()} cost: {cost.item()}')\n    ","execution_count":250,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"## loading data","execution_count":251,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"class CustomDataset(Dataset):\n    def __init__(self):\n        self.x_data = [[73,80,75],\n                       [93,88,93],\n                       [89,91,90],\n                       [96,98,100],\n                       [73,66,70]]\n        self.y_data = [[152],[185],[180],[196],[142]]\n    def __len__(self):\n        return len(self.x_data)\n    \n    def __getitem__(self, idx):\n        x = torch.FloatTensor(self.x_data[idx])\n        y = torch.FloatTensor(self.y_data[idx])\n        \n        return x,y","execution_count":252,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataset = CustomDataset()","execution_count":253,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"dataloader = DataLoader(dataset,batch_size=3, shuffle=True)","execution_count":254,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"for epoch in range(epochs +1):\n    for batch_idx, samples in enumerate(dataloader):\n        x_train3,y_train3 = samples\n        \n        prediction = model(x_train3)\n        \n        cost = F.mse_loss(prediction,y_train3)\n        \n        optimizer.zero_grad()\n        cost.backward()\n        optimizer.step()\n        \n        print(f'epoch: {epoch}/{epochs} Batch {batch_idx+1}/{len(dataloader)}, cost: {cost.item()}, prediction: {prediction}')\n        print(f'epoch: {epoch}/{epochs} Batch {batch_idx+1}/{len(dataloader)}, prediction: {prediction}')        ","execution_count":255,"outputs":[{"output_type":"stream","text":"epoch: 0/20 Batch 1/3, cost: 39036.3984375, prediction: tensor([[-51.0732],\n        [-49.9221]], grad_fn=<AddmmBackward>)\nepoch: 0/20 Batch 1/3, prediction: tensor([[-51.0732],\n        [-49.9221]], grad_fn=<AddmmBackward>)\nepoch: 0/20 Batch 2/3, cost: 29658.044921875, prediction: tensor([[15.5785],\n        [16.3290]], grad_fn=<AddmmBackward>)\nepoch: 0/20 Batch 2/3, prediction: tensor([[15.5785],\n        [16.3290]], grad_fn=<AddmmBackward>)\nepoch: 0/20 Batch 3/3, cost: 6780.29345703125, prediction: tensor([[102.6575]], grad_fn=<AddmmBackward>)\nepoch: 0/20 Batch 3/3, prediction: tensor([[102.6575]], grad_fn=<AddmmBackward>)\nepoch: 1/20 Batch 1/3, cost: 1374.17529296875, prediction: tensor([[143.8995],\n        [109.4561]], grad_fn=<AddmmBackward>)\nepoch: 1/20 Batch 1/3, prediction: tensor([[143.8995],\n        [109.4561]], grad_fn=<AddmmBackward>)\nepoch: 1/20 Batch 2/3, cost: 321.418212890625, prediction: tensor([[159.9422],\n        [136.4913]], grad_fn=<AddmmBackward>)\nepoch: 1/20 Batch 2/3, prediction: tensor([[159.9422],\n        [136.4913]], grad_fn=<AddmmBackward>)\nepoch: 1/20 Batch 3/3, cost: 187.13134765625, prediction: tensor([[182.3204]], grad_fn=<AddmmBackward>)\nepoch: 1/20 Batch 3/3, prediction: tensor([[182.3204]], grad_fn=<AddmmBackward>)\nepoch: 2/20 Batch 1/3, cost: 20.129323959350586, prediction: tensor([[190.2056],\n        [149.4148]], grad_fn=<AddmmBackward>)\nepoch: 2/20 Batch 1/3, prediction: tensor([[190.2056],\n        [149.4148]], grad_fn=<AddmmBackward>)\nepoch: 2/20 Batch 2/3, cost: 24.84395408630371, prediction: tensor([[177.3046],\n        [135.4867]], grad_fn=<AddmmBackward>)\nepoch: 2/20 Batch 2/3, prediction: tensor([[177.3046],\n        [135.4867]], grad_fn=<AddmmBackward>)\nepoch: 2/20 Batch 3/3, cost: 25.678678512573242, prediction: tensor([[179.9326]], grad_fn=<AddmmBackward>)\nepoch: 2/20 Batch 3/3, prediction: tensor([[179.9326]], grad_fn=<AddmmBackward>)\nepoch: 3/20 Batch 1/3, cost: 7.269414901733398, prediction: tensor([[182.4707],\n        [154.8533]], grad_fn=<AddmmBackward>)\nepoch: 3/20 Batch 1/3, prediction: tensor([[182.4707],\n        [154.8533]], grad_fn=<AddmmBackward>)\nepoch: 3/20 Batch 2/3, cost: 2.2792906761169434, prediction: tensor([[197.2634],\n        [181.7212]], grad_fn=<AddmmBackward>)\nepoch: 3/20 Batch 2/3, prediction: tensor([[197.2634],\n        [181.7212]], grad_fn=<AddmmBackward>)\nepoch: 3/20 Batch 3/3, cost: 13.479528427124023, prediction: tensor([[138.3286]], grad_fn=<AddmmBackward>)\nepoch: 3/20 Batch 3/3, prediction: tensor([[138.3286]], grad_fn=<AddmmBackward>)\nepoch: 4/20 Batch 1/3, cost: 8.584749221801758, prediction: tensor([[155.4132],\n        [182.3493]], grad_fn=<AddmmBackward>)\nepoch: 4/20 Batch 1/3, prediction: tensor([[155.4132],\n        [182.3493]], grad_fn=<AddmmBackward>)\nepoch: 4/20 Batch 2/3, cost: 11.348897933959961, prediction: tensor([[181.8605],\n        [138.4165]], grad_fn=<AddmmBackward>)\nepoch: 4/20 Batch 2/3, prediction: tensor([[181.8605],\n        [138.4165]], grad_fn=<AddmmBackward>)\nepoch: 4/20 Batch 3/3, cost: 4.5784220695495605, prediction: tensor([[198.1397]], grad_fn=<AddmmBackward>)\nepoch: 4/20 Batch 3/3, prediction: tensor([[198.1397]], grad_fn=<AddmmBackward>)\nepoch: 5/20 Batch 1/3, cost: 9.538249969482422, prediction: tensor([[182.1823],\n        [138.6628]], grad_fn=<AddmmBackward>)\nepoch: 5/20 Batch 1/3, prediction: tensor([[182.1823],\n        [138.6628]], grad_fn=<AddmmBackward>)\nepoch: 5/20 Batch 2/3, cost: 9.66891860961914, prediction: tensor([[198.3463],\n        [155.7192]], grad_fn=<AddmmBackward>)\nepoch: 5/20 Batch 2/3, prediction: tensor([[198.3463],\n        [155.7192]], grad_fn=<AddmmBackward>)\nepoch: 5/20 Batch 3/3, cost: 1.7715847492218018, prediction: tensor([[181.3310]], grad_fn=<AddmmBackward>)\nepoch: 5/20 Batch 3/3, prediction: tensor([[181.3310]], grad_fn=<AddmmBackward>)\nepoch: 6/20 Batch 1/3, cost: 8.252363204956055, prediction: tensor([[154.0029],\n        [181.4654]], grad_fn=<AddmmBackward>)\nepoch: 6/20 Batch 1/3, prediction: tensor([[154.0029],\n        [181.4654]], grad_fn=<AddmmBackward>)\nepoch: 6/20 Batch 2/3, cost: 0.8570114374160767, prediction: tensor([[181.1444],\n        [196.6359]], grad_fn=<AddmmBackward>)\nepoch: 6/20 Batch 2/3, prediction: tensor([[181.1444],\n        [196.6359]], grad_fn=<AddmmBackward>)\nepoch: 6/20 Batch 3/3, cost: 14.981822967529297, prediction: tensor([[138.1294]], grad_fn=<AddmmBackward>)\nepoch: 6/20 Batch 3/3, prediction: tensor([[138.1294]], grad_fn=<AddmmBackward>)\nepoch: 7/20 Batch 1/3, cost: 7.572352409362793, prediction: tensor([[155.2414],\n        [182.1536]], grad_fn=<AddmmBackward>)\nepoch: 7/20 Batch 1/3, prediction: tensor([[155.2414],\n        [182.1536]], grad_fn=<AddmmBackward>)\nepoch: 7/20 Batch 2/3, cost: 6.796927452087402, prediction: tensor([[196.4407],\n        [138.3394]], grad_fn=<AddmmBackward>)\nepoch: 7/20 Batch 2/3, prediction: tensor([[196.4407],\n        [138.3394]], grad_fn=<AddmmBackward>)\nepoch: 7/20 Batch 3/3, cost: 7.097310543060303, prediction: tensor([[182.3359]], grad_fn=<AddmmBackward>)\nepoch: 7/20 Batch 3/3, prediction: tensor([[182.3359]], grad_fn=<AddmmBackward>)\nepoch: 8/20 Batch 1/3, cost: 3.3014025688171387, prediction: tensor([[183.6702],\n        [139.8012]], grad_fn=<AddmmBackward>)\nepoch: 8/20 Batch 1/3, prediction: tensor([[183.6702],\n        [139.8012]], grad_fn=<AddmmBackward>)\nepoch: 8/20 Batch 2/3, cost: 11.899286270141602, prediction: tensor([[199.3013],\n        [183.5916]], grad_fn=<AddmmBackward>)\nepoch: 8/20 Batch 2/3, prediction: tensor([[199.3013],\n        [183.5916]], grad_fn=<AddmmBackward>)\nepoch: 8/20 Batch 3/3, cost: 8.866192817687988, prediction: tensor([[154.9776]], grad_fn=<AddmmBackward>)\nepoch: 8/20 Batch 3/3, prediction: tensor([[154.9776]], grad_fn=<AddmmBackward>)\nepoch: 9/20 Batch 1/3, cost: 14.118253707885742, prediction: tensor([[181.4123],\n        [138.0802]], grad_fn=<AddmmBackward>)\nepoch: 9/20 Batch 1/3, prediction: tensor([[181.4123],\n        [138.0802]], grad_fn=<AddmmBackward>)\nepoch: 9/20 Batch 2/3, cost: 7.167967796325684, prediction: tensor([[197.8345],\n        [155.3122]], grad_fn=<AddmmBackward>)\nepoch: 9/20 Batch 2/3, prediction: tensor([[197.8345],\n        [155.3122]], grad_fn=<AddmmBackward>)\nepoch: 9/20 Batch 3/3, cost: 1.1639662981033325, prediction: tensor([[181.0789]], grad_fn=<AddmmBackward>)\nepoch: 9/20 Batch 3/3, prediction: tensor([[181.0789]], grad_fn=<AddmmBackward>)\nepoch: 10/20 Batch 1/3, cost: 1.7754955291748047, prediction: tensor([[195.9945],\n        [153.8844]], grad_fn=<AddmmBackward>)\nepoch: 10/20 Batch 1/3, prediction: tensor([[195.9945],\n        [153.8844]], grad_fn=<AddmmBackward>)\nepoch: 10/20 Batch 2/3, cost: 17.282798767089844, prediction: tensor([[137.7330],\n        [180.9555]], grad_fn=<AddmmBackward>)\nepoch: 10/20 Batch 2/3, prediction: tensor([[137.7330],\n        [180.9555]], grad_fn=<AddmmBackward>)\nepoch: 10/20 Batch 3/3, cost: 3.8757362365722656, prediction: tensor([[181.9687]], grad_fn=<AddmmBackward>)\nepoch: 10/20 Batch 3/3, prediction: tensor([[181.9687]], grad_fn=<AddmmBackward>)\nepoch: 11/20 Batch 1/3, cost: 6.645449161529541, prediction: tensor([[138.3878],\n        [196.4929]], grad_fn=<AddmmBackward>)\nepoch: 11/20 Batch 1/3, prediction: tensor([[138.3878],\n        [196.4929]], grad_fn=<AddmmBackward>)\nepoch: 11/20 Batch 2/3, cost: 4.947704792022705, prediction: tensor([[154.7313],\n        [181.5606]], grad_fn=<AddmmBackward>)\nepoch: 11/20 Batch 2/3, prediction: tensor([[154.7313],\n        [181.5606]], grad_fn=<AddmmBackward>)\nepoch: 11/20 Batch 3/3, cost: 12.832587242126465, prediction: tensor([[181.4177]], grad_fn=<AddmmBackward>)\nepoch: 11/20 Batch 3/3, prediction: tensor([[181.4177]], grad_fn=<AddmmBackward>)\nepoch: 12/20 Batch 1/3, cost: 7.47238826751709, prediction: tensor([[183.2120],\n        [155.4275]], grad_fn=<AddmmBackward>)\nepoch: 12/20 Batch 1/3, prediction: tensor([[183.2120],\n        [155.4275]], grad_fn=<AddmmBackward>)\nepoch: 12/20 Batch 2/3, cost: 6.0262770652771, prediction: tensor([[139.2542],\n        [182.1244]], grad_fn=<AddmmBackward>)\nepoch: 12/20 Batch 2/3, prediction: tensor([[139.2542],\n        [182.1244]], grad_fn=<AddmmBackward>)\nepoch: 12/20 Batch 3/3, cost: 2.907707691192627, prediction: tensor([[197.7052]], grad_fn=<AddmmBackward>)\nepoch: 12/20 Batch 3/3, prediction: tensor([[197.7052]], grad_fn=<AddmmBackward>)\nepoch: 13/20 Batch 1/3, cost: 5.151837348937988, prediction: tensor([[182.0317],\n        [181.2219]], grad_fn=<AddmmBackward>)\nepoch: 13/20 Batch 1/3, prediction: tensor([[182.0317],\n        [181.2219]], grad_fn=<AddmmBackward>)\nepoch: 13/20 Batch 2/3, cost: 5.537980556488037, prediction: tensor([[197.1960],\n        [138.8943]], grad_fn=<AddmmBackward>)\nepoch: 13/20 Batch 2/3, prediction: tensor([[197.1960],\n        [138.8943]], grad_fn=<AddmmBackward>)\nepoch: 13/20 Batch 3/3, cost: 9.204301834106445, prediction: tensor([[155.0339]], grad_fn=<AddmmBackward>)\nepoch: 13/20 Batch 3/3, prediction: tensor([[155.0339]], grad_fn=<AddmmBackward>)\nepoch: 14/20 Batch 1/3, cost: 13.631795883178711, prediction: tensor([[181.4837],\n        [138.1400]], grad_fn=<AddmmBackward>)\nepoch: 14/20 Batch 1/3, prediction: tensor([[181.4837],\n        [138.1400]], grad_fn=<AddmmBackward>)\nepoch: 14/20 Batch 2/3, cost: 4.320590972900391, prediction: tensor([[197.8658],\n        [182.2715]], grad_fn=<AddmmBackward>)\nepoch: 14/20 Batch 2/3, prediction: tensor([[197.8658],\n        [182.2715]], grad_fn=<AddmmBackward>)\nepoch: 14/20 Batch 3/3, cost: 5.959794044494629, prediction: tensor([[154.4413]], grad_fn=<AddmmBackward>)\nepoch: 14/20 Batch 3/3, prediction: tensor([[154.4413]], grad_fn=<AddmmBackward>)\nepoch: 15/20 Batch 1/3, cost: 8.881265640258789, prediction: tensor([[180.2235],\n        [137.7914]], grad_fn=<AddmmBackward>)\nepoch: 15/20 Batch 1/3, prediction: tensor([[180.2235],\n        [137.7914]], grad_fn=<AddmmBackward>)\nepoch: 15/20 Batch 2/3, cost: 5.299537181854248, prediction: tensor([[196.4384],\n        [181.7740]], grad_fn=<AddmmBackward>)\nepoch: 15/20 Batch 2/3, prediction: tensor([[196.4384],\n        [181.7740]], grad_fn=<AddmmBackward>)\nepoch: 15/20 Batch 3/3, cost: 7.776826858520508, prediction: tensor([[154.7887]], grad_fn=<AddmmBackward>)\nepoch: 15/20 Batch 3/3, prediction: tensor([[154.7887]], grad_fn=<AddmmBackward>)\nepoch: 16/20 Batch 1/3, cost: 7.981217384338379, prediction: tensor([[138.0053],\n        [195.9319]], grad_fn=<AddmmBackward>)\nepoch: 16/20 Batch 1/3, prediction: tensor([[138.0053],\n        [195.9319]], grad_fn=<AddmmBackward>)\nepoch: 16/20 Batch 2/3, cost: 7.2966766357421875, prediction: tensor([[182.0854],\n        [154.4695]], grad_fn=<AddmmBackward>)\nepoch: 16/20 Batch 2/3, prediction: tensor([[182.0854],\n        [154.4695]], grad_fn=<AddmmBackward>)\nepoch: 16/20 Batch 3/3, cost: 2.1782095432281494, prediction: tensor([[181.4759]], grad_fn=<AddmmBackward>)\nepoch: 16/20 Batch 3/3, prediction: tensor([[181.4759]], grad_fn=<AddmmBackward>)\nepoch: 17/20 Batch 1/3, cost: 13.043655395507812, prediction: tensor([[181.5737],\n        [138.2121]], grad_fn=<AddmmBackward>)\nepoch: 17/20 Batch 1/3, prediction: tensor([[181.5737],\n        [138.2121]], grad_fn=<AddmmBackward>)\nepoch: 17/20 Batch 2/3, cost: 8.30887222290039, prediction: tensor([[182.3156],\n        [155.3550]], grad_fn=<AddmmBackward>)\nepoch: 17/20 Batch 2/3, prediction: tensor([[182.3156],\n        [155.3550]], grad_fn=<AddmmBackward>)\nepoch: 17/20 Batch 3/3, cost: 0.3049420416355133, prediction: tensor([[196.5522]], grad_fn=<AddmmBackward>)\nepoch: 17/20 Batch 3/3, prediction: tensor([[196.5522]], grad_fn=<AddmmBackward>)\nepoch: 18/20 Batch 1/3, cost: 2.40024733543396, prediction: tensor([[180.7718],\n        [154.0506]], grad_fn=<AddmmBackward>)\nepoch: 18/20 Batch 1/3, prediction: tensor([[180.7718],\n        [154.0506]], grad_fn=<AddmmBackward>)\nepoch: 18/20 Batch 2/3, cost: 9.100676536560059, prediction: tensor([[195.5714],\n        [137.7553]], grad_fn=<AddmmBackward>)\nepoch: 18/20 Batch 2/3, prediction: tensor([[195.5714],\n        [137.7553]], grad_fn=<AddmmBackward>)\nepoch: 18/20 Batch 3/3, cost: 9.614106178283691, prediction: tensor([[181.8993]], grad_fn=<AddmmBackward>)\nepoch: 18/20 Batch 3/3, prediction: tensor([[181.8993]], grad_fn=<AddmmBackward>)\nepoch: 19/20 Batch 1/3, cost: 4.5878424644470215, prediction: tensor([[183.4523],\n        [182.6039]], grad_fn=<AddmmBackward>)\nepoch: 19/20 Batch 1/3, prediction: tensor([[183.4523],\n        [182.6039]], grad_fn=<AddmmBackward>)\nepoch: 19/20 Batch 2/3, cost: 7.634685039520264, prediction: tensor([[197.9559],\n        [155.3829]], grad_fn=<AddmmBackward>)\nepoch: 19/20 Batch 2/3, prediction: tensor([[197.9559],\n        [155.3829]], grad_fn=<AddmmBackward>)\nepoch: 19/20 Batch 3/3, cost: 12.136935234069824, prediction: tensor([[138.5162]], grad_fn=<AddmmBackward>)\nepoch: 19/20 Batch 3/3, prediction: tensor([[138.5162]], grad_fn=<AddmmBackward>)\nepoch: 20/20 Batch 1/3, cost: 5.131107807159424, prediction: tensor([[198.0629],\n        [182.4509]], grad_fn=<AddmmBackward>)\nepoch: 20/20 Batch 1/3, prediction: tensor([[198.0629],\n        [182.4509]], grad_fn=<AddmmBackward>)\nepoch: 20/20 Batch 2/3, cost: 8.737860679626465, prediction: tensor([[138.6492],\n        [154.4996]], grad_fn=<AddmmBackward>)\nepoch: 20/20 Batch 2/3, prediction: tensor([[138.6492],\n        [154.4996]], grad_fn=<AddmmBackward>)\nepoch: 20/20 Batch 3/3, cost: 7.495426654815674, prediction: tensor([[182.2622]], grad_fn=<AddmmBackward>)\nepoch: 20/20 Batch 3/3, prediction: tensor([[182.2622]], grad_fn=<AddmmBackward>)\n","name":"stdout"}]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"}},"nbformat":4,"nbformat_minor":4}