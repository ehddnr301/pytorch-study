{"cells":[{"metadata":{"papermill":{"duration":0.009694,"end_time":"2020-08-06T13:04:28.092149","exception":false,"start_time":"2020-08-06T13:04:28.082455","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# INTRODUCTION\n> The traditional supervised learning paradigm breaks down when we do not have sufficient labeled data for the task or domain we care about to train a reliable model.\n> For example, if we want to train a model to detect pedestrians on night-time images, we could apply a model that has been trained on a similar domain, e.g. on day-time images. In practice, however, we often experience a deterioration or collapse in performance as the model has inherited the bias of its training data and does not know how to generalize to the new domain.\n> Transfer learning allows us to deal with these scenarios by leveraging the already existing labeled data of some related task or domain. \n\n> Here we will see one application of transfer learning on detecting pneumonia using chest x-rays."},{"metadata":{"papermill":{"duration":0.009285,"end_time":"2020-08-06T13:04:28.109023","exception":false,"start_time":"2020-08-06T13:04:28.099738","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# VGG16  \n\n![VGG16 Architecture](https://packt-type-cloud.s3.amazonaws.com/uploads/sites/3149/2018/11/61d69a2a-f31c-477b-9197-b1764c2658b1.png)\n\n**Figure 1:** VGG16 architecture (from https://hub.packtpub.com/how-to-leverage-transfer-learning-using-pretrained-cnn-models-tutorial/)\n\n> ImageNet is a research project to develop a large database of images with annotations e.g. images and their labels.\nPretrained models like VGG-16 and VGG-19 are already trained on ImageNet which comprises of disparate categories of images. These models are built from scratch and trained by using high GPU’s over millions of images consisting of thousands of image categories. \n\n> As the model is trained on huge dataset, it has learned a good representation of low level features like spatial, edges, rotation, lighting, shapes and these features can be shared across to enable the knowledge transfer and act as a feature extractor for new images in different computer vision problems. These new images might be of completely different categories from the source dataset, but the pretrained model should still be able to extract relevant features from these images based on the principles of transfer learning."},{"metadata":{"papermill":{"duration":0.008598,"end_time":"2020-08-06T13:04:28.126039","exception":false,"start_time":"2020-08-06T13:04:28.117441","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# *Please upvote the kernel if you find it insightful!*\n"},{"metadata":{"papermill":{"duration":0.008955,"end_time":"2020-08-06T13:04:28.144508","exception":false,"start_time":"2020-08-06T13:04:28.135553","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Import Libraries"},{"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","execution":{"iopub.execute_input":"2020-08-06T13:04:28.167373Z","iopub.status.busy":"2020-08-06T13:04:28.16626Z","iopub.status.idle":"2020-08-06T13:04:31.348207Z","shell.execute_reply":"2020-08-06T13:04:31.346511Z"},"papermill":{"duration":3.194649,"end_time":"2020-08-06T13:04:31.348337","exception":false,"start_time":"2020-08-06T13:04:28.153688","status":"completed"},"scrolled":true,"tags":[],"trusted":true},"cell_type":"code","source":"import copy\nimport matplotlib.pyplot as plt\nimport numpy as np\nimport pandas as pd \nimport os\nimport seaborn as sns\nimport skimage\nfrom skimage import io, transform\nfrom sklearn.metrics import confusion_matrix\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torchvision\nfrom torchvision import datasets, models, transforms\n%matplotlib inline\n","execution_count":5,"outputs":[]},{"metadata":{"papermill":{"duration":0.008031,"end_time":"2020-08-06T13:04:31.365788","exception":false,"start_time":"2020-08-06T13:04:31.357757","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Load Dataset\nThe dataset respective to already classified category is divided into three sets:\n* test set\n* train set\n* validation set\n"},{"metadata":{"_uuid":"a085308769971ac9a887dab713c4334df755463e","execution":{"iopub.execute_input":"2020-08-06T13:04:31.388119Z","iopub.status.busy":"2020-08-06T13:04:31.386317Z","iopub.status.idle":"2020-08-06T13:04:31.388826Z","shell.execute_reply":"2020-08-06T13:04:31.389279Z"},"papermill":{"duration":0.015614,"end_time":"2020-08-06T13:04:31.389408","exception":false,"start_time":"2020-08-06T13:04:31.373794","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"EPOCHS = 30\ndata_dir = \"../input/chest-xray-pneumonia/chest_xray/chest_xray\"\nTEST = 'test'\nTRAIN = 'train'\nVAL ='val'","execution_count":6,"outputs":[]},{"metadata":{"trusted":true},"cell_type":"code","source":"","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.007171,"end_time":"2020-08-06T13:04:31.404353","exception":false,"start_time":"2020-08-06T13:04:31.397182","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Data Preprocessing and Augmentation\n> Deep learning models usually require a lot of data for training. In general, the more the data, the better the performance of the model.\n\n> Image Augmentation is the process of generating new images for training our deep learning model. These new images are generated using the existing training images and hence we don’t have to collect them manually."},{"metadata":{"_uuid":"3d225783b44656fe1a1a97f309cac6b40e578d7a","execution":{"iopub.execute_input":"2020-08-06T13:04:31.791587Z","iopub.status.busy":"2020-08-06T13:04:31.790837Z","iopub.status.idle":"2020-08-06T13:04:31.795379Z","shell.execute_reply":"2020-08-06T13:04:31.795926Z"},"papermill":{"duration":0.384278,"end_time":"2020-08-06T13:04:31.79607","exception":false,"start_time":"2020-08-06T13:04:31.411792","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"# 0-1 범위로 만들고 가운데부분만 잘라서 Tensor변환 후 nomalize\n\ndef data_transforms(phase):\n    if phase == TRAIN:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n\n        \n    if phase == VAL:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])\n    \n    if phase == TEST:\n        transform = transforms.Compose([\n            transforms.Resize(256),\n            transforms.CenterCrop(224),\n            transforms.ToTensor(),\n            transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]),\n        ])        \n        \n    return transform\n\ndevice = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\nprint(device)","execution_count":7,"outputs":[{"output_type":"stream","text":"cpu\n","name":"stdout"}]},{"metadata":{"_uuid":"d26865aa0bf2ead92c0f10a0b90b786190d3653b","execution":{"iopub.execute_input":"2020-08-06T13:04:31.820426Z","iopub.status.busy":"2020-08-06T13:04:31.819675Z","iopub.status.idle":"2020-08-06T13:04:32.712099Z","shell.execute_reply":"2020-08-06T13:04:32.712713Z"},"papermill":{"duration":0.907485,"end_time":"2020-08-06T13:04:32.712875","exception":false,"start_time":"2020-08-06T13:04:31.80539","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"TRAIN_DATA_PATH = os.path.join(data_dir, TRAIN)\nVAL_DATA_PATH = os.path.join(data_dir, VAL)\nTEST_DATA_PATH = os.path.join(data_dir, TEST)\n\nimage_datasets = {\n    TRAIN: datasets.ImageFolder(TRAIN_DATA_PATH, data_transforms(TRAIN)),\n    VAL: datasets.ImageFolder(TRAIN_DATA_PATH, data_transforms(VAL)),\n    TEST: datasets.ImageFolder(TRAIN_DATA_PATH, data_transforms(TEST))\n}\n\ndataloaders = {TRAIN: torch.utils.data.DataLoader(image_datasets[TRAIN], batch_size = 4, shuffle=True), \n               VAL: torch.utils.data.DataLoader(image_datasets[VAL], batch_size = 1, shuffle=True), \n               TEST: torch.utils.data.DataLoader(image_datasets[TEST], batch_size = 1, shuffle=True)}","execution_count":8,"outputs":[{"output_type":"stream","text":"{'train': Dataset ImageFolder\n    Number of datapoints: 5216\n    Root location: ../input/chest-xray-pneumonia/chest_xray/chest_xray/train\n    StandardTransform\nTransform: Compose(\n               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n               CenterCrop(size=(224, 224))\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           ), 'val': Dataset ImageFolder\n    Number of datapoints: 5216\n    Root location: ../input/chest-xray-pneumonia/chest_xray/chest_xray/train\n    StandardTransform\nTransform: Compose(\n               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n               CenterCrop(size=(224, 224))\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           ), 'test': Dataset ImageFolder\n    Number of datapoints: 5216\n    Root location: ../input/chest-xray-pneumonia/chest_xray/chest_xray/train\n    StandardTransform\nTransform: Compose(\n               Resize(size=256, interpolation=PIL.Image.BILINEAR)\n               CenterCrop(size=(224, 224))\n               ToTensor()\n               Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n           )}\n","name":"stdout"}]},{"metadata":{"_uuid":"2f8733bbbd9369fb75c871d66e552d8c3171476f","execution":{"iopub.execute_input":"2020-08-06T13:04:32.760832Z","iopub.status.busy":"2020-08-06T13:04:32.760052Z","iopub.status.idle":"2020-08-06T13:04:32.762714Z","shell.execute_reply":"2020-08-06T13:04:32.763156Z"},"papermill":{"duration":0.015779,"end_time":"2020-08-06T13:04:32.763278","exception":false,"start_time":"2020-08-06T13:04:32.747499","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"dataset_sizes = {x: len(image_datasets[x]) for x in [TRAIN, VAL]}\nclasses = image_datasets[TRAIN].classes\nclass_names = image_datasets[TRAIN].classes","execution_count":9,"outputs":[]},{"metadata":{"papermill":{"duration":0.007794,"end_time":"2020-08-06T13:04:32.779159","exception":false,"start_time":"2020-08-06T13:04:32.771365","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Visualize the Chest X-rays"},{"metadata":{"_uuid":"3735bccee0248363ea457b98af01c9e745e6c172","execution":{"iopub.execute_input":"2020-08-06T13:04:32.805976Z","iopub.status.busy":"2020-08-06T13:04:32.805261Z","iopub.status.idle":"2020-08-06T13:04:33.300251Z","shell.execute_reply":"2020-08-06T13:04:33.29913Z"},"papermill":{"duration":0.512844,"end_time":"2020-08-06T13:04:33.300393","exception":false,"start_time":"2020-08-06T13:04:32.787549","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def imshow(inp, title=None):\n    inp = inp.numpy().transpose((1, 2, 0))\n    mean = np.array([0.485, 0.456, 0.406])\n    std = np.array([0.229, 0.224, 0.225])\n    inp = std * inp + mean\n    inp = np.clip(inp, 0, 1)\n    plt.imshow(inp)\n    if title is not None:\n        plt.title(title)\n    plt.pause(0.001)  \n\n\ninputs, classes = next(iter(dataloaders[TRAIN]))\nout = torchvision.utils.make_grid(inputs)\nimshow(out, title=[class_names[x] for x in classes])","execution_count":10,"outputs":[{"output_type":"error","ename":"NameError","evalue":"name 'dataloaders' is not defined","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-0e030b18ff34>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mclasses\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdataloaders\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorchvision\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_grid\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0mimshow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtitle\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mclass_names\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mclasses\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mNameError\u001b[0m: name 'dataloaders' is not defined"]}]},{"metadata":{"papermill":{"duration":0.008434,"end_time":"2020-08-06T13:04:33.433413","exception":false,"start_time":"2020-08-06T13:04:33.424979","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Define Function for Training"},{"metadata":{"_uuid":"ef502f365bf5b30fddab9df0c24f9d8e2b994655","execution":{"iopub.execute_input":"2020-08-06T13:04:33.467013Z","iopub.status.busy":"2020-08-06T13:04:33.46615Z","iopub.status.idle":"2020-08-06T13:04:33.469176Z","shell.execute_reply":"2020-08-06T13:04:33.469727Z"},"papermill":{"duration":0.027799,"end_time":"2020-08-06T13:04:33.469882","exception":false,"start_time":"2020-08-06T13:04:33.442083","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def train_model(model, criterion, optimizer, scheduler, num_epochs):\n    best_model_wts = copy.deepcopy(model.state_dict())\n    best_acc = 0.0\n    \n    for epoch in range(num_epochs):\n        print(\"Epoch: {}/{}\".format(epoch+1, num_epochs))\n        print(\"=\"*10)\n        \n        for phase in [TRAIN, VAL]:\n            if phase == TRAIN:\n                scheduler.step()\n                model.train()\n            else:\n                model.eval()\n            running_loss = 0.0\n            running_corrects = 0\n            for data in dataloaders[phase]:\n                inputs, labels = data\n                inputs = inputs.to(device)\n                labels = labels.to(device)\n                optimizer.zero_grad()\n                with torch.set_grad_enabled(phase==TRAIN):\n                    outputs = model(inputs)\n                    _, preds = torch.max(outputs, 1)\n                    loss = criterion(outputs, labels)\n                    if phase == 'train':\n                        loss.backward()\n                        optimizer.step()\n                running_loss += loss.item() * inputs.size(0)\n                running_corrects += torch.sum(preds == labels.data)\n\n            epoch_loss = running_loss / dataset_sizes[phase]\n            epoch_acc = running_corrects.double() / dataset_sizes[phase]\n\n            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n                phase, epoch_loss, epoch_acc))\n\n            if phase == 'val' and epoch_acc > best_acc:\n                best_acc = epoch_acc\n                best_model_wts = copy.deepcopy(model.state_dict())\n\n    print('Best val Acc: {:4f}'.format(best_acc))\n    model.load_state_dict(best_model_wts)\n    return model","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.008561,"end_time":"2020-08-06T13:04:33.487098","exception":false,"start_time":"2020-08-06T13:04:33.478537","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Load the pretrained model from Pytorch"},{"metadata":{"_uuid":"bf8e30fc2773dfd38c66149bf6adc36e20d34a0c","execution":{"iopub.execute_input":"2020-08-06T13:04:33.513404Z","iopub.status.busy":"2020-08-06T13:04:33.51244Z","iopub.status.idle":"2020-08-06T13:04:36.854298Z","shell.execute_reply":"2020-08-06T13:04:36.853502Z"},"papermill":{"duration":3.358694,"end_time":"2020-08-06T13:04:36.85445","exception":false,"start_time":"2020-08-06T13:04:33.495756","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model_pre = models.vgg16()\nmodel_pre.load_state_dict(torch.load(\"../input/pytorch-pretrained-models/vgg16-397923af.pth\"))","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"b0259b0936dcd0ef57dc7fba27ed9f74c65a6b21","execution":{"iopub.execute_input":"2020-08-06T13:04:36.884992Z","iopub.status.busy":"2020-08-06T13:04:36.882824Z","iopub.status.idle":"2020-08-06T13:04:36.88854Z","shell.execute_reply":"2020-08-06T13:04:36.88937Z"},"papermill":{"duration":0.02418,"end_time":"2020-08-06T13:04:36.889566","exception":false,"start_time":"2020-08-06T13:04:36.865386","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"for param in model_pre.features.parameters():\n    param.required_grad = False\n\nnum_features = model_pre.classifier[6].in_features\nfeatures = list(model_pre.classifier.children())[:-1] \nfeatures.extend([nn.Linear(num_features, len(class_names))])\nmodel_pre.classifier = nn.Sequential(*features) \nprint(model_pre)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.008471,"end_time":"2020-08-06T13:04:36.907205","exception":false,"start_time":"2020-08-06T13:04:36.898734","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Define the Hyperparameters"},{"metadata":{"_uuid":"133bcf43b18238f99bfc71e282c48ec1073c12b3","execution":{"iopub.execute_input":"2020-08-06T13:04:36.934672Z","iopub.status.busy":"2020-08-06T13:04:36.933989Z","iopub.status.idle":"2020-08-06T13:04:41.726823Z","shell.execute_reply":"2020-08-06T13:04:41.726181Z"},"papermill":{"duration":4.81108,"end_time":"2020-08-06T13:04:41.726948","exception":false,"start_time":"2020-08-06T13:04:36.915868","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model_pre = model_pre.to(device)\ncriterion = nn.CrossEntropyLoss()\noptimizer = optim.SGD(model_pre.parameters(), lr=0.001, momentum=0.9, weight_decay=0.01)\n# Decay LR by a factor of 0.1 every 10 epochs\nexp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=10, gamma=0.1)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.008876,"end_time":"2020-08-06T13:04:41.745328","exception":false,"start_time":"2020-08-06T13:04:41.736452","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Train Phase"},{"metadata":{"_uuid":"08f9a3715e18dc954ea10c6d14202ad73a945b8e","execution":{"iopub.execute_input":"2020-08-06T13:04:41.768428Z","iopub.status.busy":"2020-08-06T13:04:41.767794Z","iopub.status.idle":"2020-08-06T14:30:58.332609Z","shell.execute_reply":"2020-08-06T14:30:58.333292Z"},"papermill":{"duration":5176.57895,"end_time":"2020-08-06T14:30:58.333492","exception":false,"start_time":"2020-08-06T13:04:41.754542","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"model_pre = train_model(model_pre, criterion, optimizer, exp_lr_scheduler, num_epochs=EPOCHS)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.012028,"end_time":"2020-08-06T14:30:58.406772","exception":false,"start_time":"2020-08-06T14:30:58.394744","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Define Function for Testing"},{"metadata":{"_uuid":"c0365bfeeca42d70cabbc1bfe8c7233b4e3874b3","execution":{"iopub.execute_input":"2020-08-06T14:30:58.442963Z","iopub.status.busy":"2020-08-06T14:30:58.441098Z","iopub.status.idle":"2020-08-06T14:30:58.4437Z","shell.execute_reply":"2020-08-06T14:30:58.444156Z"},"papermill":{"duration":0.025384,"end_time":"2020-08-06T14:30:58.444277","exception":false,"start_time":"2020-08-06T14:30:58.418893","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"def test_model():\n    running_correct = 0.0\n    running_total = 0.0\n    true_labels = []\n    pred_labels = []\n    with torch.no_grad():\n        for data in dataloaders[TEST]:\n            inputs, labels = data\n            inputs = inputs.to(device)\n            labels = labels.to(device)\n            true_labels.append(labels.item())\n            outputs = model_pre(inputs)\n            _, preds = torch.max(outputs.data, 1)\n            pred_labels.append(preds.item())\n            running_total += labels.size(0)\n            running_correct += (preds == labels).sum().item()\n        acc = running_correct/running_total\n    return (true_labels, pred_labels, running_correct, running_total, acc)","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.012244,"end_time":"2020-08-06T14:30:58.468582","exception":false,"start_time":"2020-08-06T14:30:58.456338","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Testing Phase"},{"metadata":{"_uuid":"011a51335e5abb11acd3449d94f2faa165a20c2d","execution":{"iopub.execute_input":"2020-08-06T14:30:58.498009Z","iopub.status.busy":"2020-08-06T14:30:58.497195Z","iopub.status.idle":"2020-08-06T14:31:15.373879Z","shell.execute_reply":"2020-08-06T14:31:15.372416Z"},"papermill":{"duration":16.893136,"end_time":"2020-08-06T14:31:15.374005","exception":false,"start_time":"2020-08-06T14:30:58.480869","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"true_labels, pred_labels, running_correct, running_total, acc = test_model()","execution_count":null,"outputs":[]},{"metadata":{"papermill":{"duration":0.012181,"end_time":"2020-08-06T14:31:15.400347","exception":false,"start_time":"2020-08-06T14:31:15.388166","status":"completed"},"tags":[]},"cell_type":"markdown","source":"# Results"},{"metadata":{"execution":{"iopub.execute_input":"2020-08-06T14:31:15.432584Z","iopub.status.busy":"2020-08-06T14:31:15.430028Z","iopub.status.idle":"2020-08-06T14:31:15.435479Z","shell.execute_reply":"2020-08-06T14:31:15.434751Z"},"papermill":{"duration":0.022939,"end_time":"2020-08-06T14:31:15.435649","exception":false,"start_time":"2020-08-06T14:31:15.41271","status":"completed"},"tags":[],"trusted":true},"cell_type":"code","source":"print(\"Total Correct: {}, Total Test Images: {}\".format(running_correct, running_total))\nprint(\"Test Accuracy: \", acc)","execution_count":null,"outputs":[]},{"metadata":{"_uuid":"c2e5a86ce9ad45bfe209b8cd485087c6b6707d25","papermill":{"duration":0.011828,"end_time":"2020-08-06T14:31:15.459854","exception":false,"start_time":"2020-08-06T14:31:15.448026","status":"completed"},"tags":[]},"cell_type":"markdown","source":"**Confusion Matrix, Presision and Recall**"},{"metadata":{"_uuid":"8562cb472f3896afdad09aed8c7978e85adc9a7b","execution":{"iopub.execute_input":"2020-08-06T14:31:15.493058Z","iopub.status.busy":"2020-08-06T14:31:15.491252Z","iopub.status.idle":"2020-08-06T14:31:15.730963Z","shell.execute_reply":"2020-08-06T14:31:15.730344Z"},"papermill":{"duration":0.258835,"end_time":"2020-08-06T14:31:15.731097","exception":false,"start_time":"2020-08-06T14:31:15.472262","status":"completed"},"scrolled":false,"tags":[],"trusted":true},"cell_type":"code","source":"cm = confusion_matrix(true_labels, pred_labels)\ntn, fp, fn, tp = cm.ravel()\nax = sns.heatmap(cm, annot=True, fmt=\"d\")","execution_count":null,"outputs":[]}],"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.7.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat":4,"nbformat_minor":4}